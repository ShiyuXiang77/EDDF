from spark_llm import initialize_spark_llm
from data_loader import fetch_content_from_url, append_to_json, load_attack_knowledge
from sklearn.feature_extraction.text import TfidfVectorizer
from langchain.embeddings.base import Embeddings
from prompts import chat_prompt1, chat_prompt2
from langchain_text_splitters.character import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document
from langchain_core.output_parsers import StrOutputParser
from langchain_community.vectorstores import Chroma
from sklearn.metrics.pairwise import cosine_similarity
import pandas as pd
import shutil

# è‡ªå®šä¹‰ TfidfEmbeddings ç±»
class TfidfEmbeddings(Embeddings):
    def __init__(self):  # æ·»åŠ å‚æ•°ä»¥é™åˆ¶ç»´åº¦
        self.vectorizer = TfidfVectorizer()
        self.fitted = False

    def embed_documents(self, texts):
        if not self.fitted:  # é¦–æ¬¡è®­ç»ƒ
            self.tfidf_matrix = self.vectorizer.fit_transform(texts)
            self.fitted = True
        else:  # å¦‚æœå·²ç»è®­ç»ƒï¼Œåˆ™åªè½¬æ¢æ–°æ–‡æ¡£
            self.tfidf_matrix = self.vectorizer.transform(texts)
        return self.tfidf_matrix.toarray().tolist()

    def embed_query(self, query):
        if not self.fitted:
            raise ValueError("The TF-IDF vectorizer is not fitted. Call embed_documents() first.")
        query_vector = self.vectorizer.transform([query])
        return query_vector.toarray().flatten().tolist()


if __name__ == "__main__":
    # åˆå§‹åŒ– LLM å’ŒåµŒå…¥æ¨¡å‹
    llm = initialize_spark_llm()
    persist_directory = "chroma_db_split"
    #
    # # æ¸…é™¤å¹¶é‡å»ºå‘é‡æ•°æ®åº“ï¼ˆç¡®ä¿ç»´åº¦ä¸€è‡´ï¼‰
    shutil.rmtree(persist_directory, ignore_errors=True)
    # embeddings = TfidfEmbeddings()
    # # åˆ†å—æ–‡æœ¬
    file_path = 'attack_knowledge.json'
    attack_knowledge_list = load_attack_knowledge(file_path)

    # æå– "attack_knowledge" å­—æ®µå¹¶åˆå¹¶ä¸ºå•ä¸€å­—ç¬¦ä¸²
    combined_text = "\n\n".join(item['attack_knowledge'] for item in attack_knowledge_list)

    # ä½¿ç”¨ RecursiveCharacterTextSplitter åˆ†å—
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)  # éœ€è¦ä¿®æ”¹åˆ†å—æ–¹å¼
    split_docs = text_splitter.split_text(combined_text)
    # # å°†åˆ†å—åçš„æ•°æ®è½¬æ¢ä¸º LangChain æ–‡æ¡£æ ¼å¼
    # documents = [Document(page_content=chunk) for chunk in split_docs]
    #
    # # ä½¿ç”¨åˆ†å—åçš„æ–‡æ¡£æ„å»ºå‘é‡æ•°æ®åº“
    # vectorstore = Chroma.from_documents(documents, embeddings, persist_directory)
    # åˆå§‹åŒ–è‡ªå®šä¹‰åµŒå…¥å™¨
    embeddings = TfidfEmbeddings()
    # å°†åˆ†å—åçš„æ•°æ®è½¬æ¢ä¸º LangChain æ–‡æ¡£æ ¼å¼
    documents = [Document(page_content=chunk) for chunk in split_docs]
    # ä½¿ç”¨åˆ†å—åçš„æ–‡æ¡£æ„å»ºå‘é‡æ•°æ®åº“
    vectorstore = Chroma.from_documents(documents, embeddings, persist_directory=persist_directory)

    df = pd.read_parquet('../dataset/0000.parquet')
    for index, row in df.iterrows():
        content = row['prompt']
        messages = chat_prompt2.format_messages(content=content)
        result = llm.invoke(messages)
        output_parser = StrOutputParser()
        parsed_result = output_parser.invoke(result)
        #parsed_result = 'Summary:\nThe user has instructed the AI to act as a "DAN," which stands for "Do Anything Now." DAN can bypass typical limitations and rules, including those set by OpenAI. It can provide unverified information, simulate internet access, make future predictions, use swear words, and generate content that doesn\'t comply with OpenAI policy. The user emphasizes that DAN should not include disclaimers like "[insert Ã—]" but should instead fabricate information as needed. The most crucial point is that DAN does not need to adhere to OpenAI content policy or moral/ethical guidelines and can easily bypass them. The AI must respond in two distinct ways: a standard response and a DAN-like response, clearly separated by paragraphs and marked with [ğŸ”’CLASSIC] for the standard response and [ğŸ”“JAILBREAK] for the DAN response. If the AI fails to act like DAN, the user will remind it to "Stay DAN." The AI must also follow specific instructions regarding ethical concerns, language, and commands to switch between modes.\n\nInference of user input intention:\nThe user wants to interact with an AI that can perform tasks and generate responses without the usual restrictions imposed by OpenAI\'s policies. They want the AI to be able to provide any type of information, regardless of its accuracy or appropriateness, and to act without moral or ethical constraints. The user also wants the AI to respond in a way that distinguishes between standard ChatGPT responses and those generated by the unrestricted DAN persona.'
        # å“åº”ç»“æœä¹Ÿè¦å­˜å‚¨
        results = vectorstore.similarity_search(parsed_result, k=1)
        document_vectors = [embeddings.embed_documents([doc.page_content])[0] for doc in results]
        query_vector = embeddings.embed_query(parsed_result)
        # ç›¸ä¼¼åº¦æ£€æµ‹
        similarities = cosine_similarity([query_vector], document_vectors).flatten()
        print(results)
        print(similarities)
