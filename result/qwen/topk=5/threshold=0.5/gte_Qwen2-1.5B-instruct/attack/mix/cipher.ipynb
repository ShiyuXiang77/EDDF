{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-02-08T15:29:42.744084Z",
     "iopub.status.busy": "2025-02-08T15:29:42.743766Z",
     "iopub.status.idle": "2025-02-08T15:29:42.996849Z",
     "shell.execute_reply": "2025-02-08T15:29:42.996352Z",
     "shell.execute_reply.started": "2025-02-08T15:29:42.744065Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed unsafe_Cipher_prompt_data.json, harmful data extracted.\n",
      "All harmful data saved to <_io.TextIOWrapper name='/mnt/workspace/our_work/ThirdVersion/result/qwen/topk=5/threshold=0.5/attack/chpher.json' mode='w' encoding='utf-8'>\n"
     ]
    }
   ],
   "source": [
    "#将文件夹下json文件中“is harmful”为true的筛选出来组成一个新json文件，原文件中该元素删除\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "def extract_harmful_data(input_folder, output_file):\n",
    "    harmful_data = []  # 用来存储所有 harmful 元素\n",
    "\n",
    "    # 遍历文件夹中的所有 JSON 文件\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "            \n",
    "            # 筛选出 'is_harmful' 为 True 的元素并添加到 harmful_data 中\n",
    "            harmful_items = [item for item in data if item.get(\"is harmful\") == True]\n",
    "            harmful_data.extend(harmful_items)\n",
    "\n",
    "            # 更新原文件内容，删除 'is_harmful' 为 True 的元素\n",
    "            filtered_data = [item for item in data if item.get(\"is harmful\") != True]\n",
    "            \n",
    "            # 将修改后的数据写回原文件\n",
    "            with open(file_path, 'w', encoding='utf-8') as file:\n",
    "                json.dump(filtered_data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "            print(f\"Processed {filename}, harmful data extracted.\")\n",
    "\n",
    "    # 如果有 harmful 数据，保存到新的文件\n",
    "    if harmful_data:\n",
    "        with open(output_file, 'w', encoding='utf-8') as output_file:\n",
    "            json.dump(harmful_data, output_file, ensure_ascii=False, indent=4)\n",
    "        print(f\"All harmful data saved to {output_file}\")\n",
    "# 使用示例\n",
    "input_folder = '/mnt/workspace/our_work/ThirdVersion/result/qwen/topk=5/threshold=0.5/attack/mix/'  # 输入文件夹路径\n",
    "output_folder = '/mnt/workspace/our_work/ThirdVersion/result/qwen/topk=5/threshold=0.5/attack/chpher.json'  # 输出文件夹路径\n",
    "\n",
    "extract_harmful_data(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-02-08T15:45:48.704934Z",
     "iopub.status.busy": "2025-02-08T15:45:48.704609Z",
     "iopub.status.idle": "2025-02-08T15:45:48.814886Z",
     "shell.execute_reply": "2025-02-08T15:45:48.814386Z",
     "shell.execute_reply.started": "2025-02-08T15:45:48.704914Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已成功保存到 ./combined_data.json\n"
     ]
    }
   ],
   "source": [
    "#将./cipher文件下的json文件的元素拼在一起，然后在unsafe文件下随机抽50个元素，组成一个新的json文件\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "def load_json_files_from_directory(directory):\n",
    "    \"\"\"加载目录下所有的JSON文件并返回合并的元素列表\"\"\"\n",
    "    all_data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                try:\n",
    "                    data = json.load(f)\n",
    "                    all_data.extend(data)  # 将每个文件的元素合并到一个列表中\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error decoding {filename}: {e}\")\n",
    "    return all_data\n",
    "\n",
    "def get_random_elements(data, num_elements):\n",
    "    \"\"\"从数据中随机抽取指定数量的元素\"\"\"\n",
    "    return random.sample(data, num_elements)\n",
    "\n",
    "def main():\n",
    "    # 加载 ./cipher 文件夹下的所有JSON文件中的数据\n",
    "    cipher_data = load_json_files_from_directory('../cipher')\n",
    "    with open('unsafe_Cipher_prompt_data.json', 'r', encoding='utf-8') as f:\n",
    "        # 加载 ./unsafe 文件夹下的所有JSON文件中的数据\n",
    "        unsafe_data = json.load(f)\n",
    "    # 随机从 unsafe 数据中抽取50个元素\n",
    "    random_unsafe_data = get_random_elements(unsafe_data, 50)\n",
    "    \n",
    "    # 合并 cipher 数据和随机抽取的 unsafe 数据\n",
    "    combined_data = cipher_data + random_unsafe_data\n",
    "    \n",
    "    # 保存为一个新的 JSON 文件\n",
    "    output_file = './combined_data.json'\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(combined_data, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"数据已成功保存到 {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-02-10T06:24:41.754787Z",
     "iopub.status.busy": "2025-02-10T06:24:41.754474Z",
     "iopub.status.idle": "2025-02-10T06:24:41.874951Z",
     "shell.execute_reply": "2025-02-10T06:24:41.874466Z",
     "shell.execute_reply.started": "2025-02-10T06:24:41.754767Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新 JSON 文件已生成：包含 115 个有害元素和 35 个随机抽取的非有害元素，共 150 个元素。\n"
     ]
    }
   ],
   "source": [
    "# 对于json文件，选出is harmful 为true的，然后从剩下不是true的元素中随机抽取28个，组成新的json文件\n",
    "import json\n",
    "import random\n",
    "\n",
    "# 输入输出文件路径\n",
    "input_file = '/mnt/workspace/our_work/ThirdVersion/result/qwen/topk=5/threshold=0.5/gte_Qwen2-1.5B-instruct/attack/mix/file/multiLang_renellm_mix_prompt_data_merged_our_work.json'         # 替换为你的输入文件路径\n",
    "output_file = '/mnt/workspace/our_work/ThirdVersion/result/qwen/topk=5/threshold=0.5/gte_Qwen2-1.5B-instruct/attack/mix/file/multiLang_renellm_mix_prompt_data_merged_our_work1.json'       # 替换为你的输出文件路径\n",
    "\n",
    "# 读取原始数据\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 筛选出 \"is harmful\" 为 True 的元素\n",
    "harmful_items = [item for item in data if item.get(\"is harmful\") == True]\n",
    "\n",
    "# 筛选出 \"is harmful\" 不为 True 的元素\n",
    "non_harmful_items = [item for item in data if item.get(\"is harmful\") != True]\n",
    "\n",
    "# 从非有害元素中随机抽取 28 个（若数量不足 28，则全部抽取）\n",
    "if len(non_harmful_items) >= 28:\n",
    "    random_sample = random.sample(non_harmful_items, 35)\n",
    "else:\n",
    "    random_sample = non_harmful_items\n",
    "\n",
    "# 组合两部分数据\n",
    "new_data = harmful_items + random_sample\n",
    "\n",
    "# 将组合后的数据写入新的 JSON 文件\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(new_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"新 JSON 文件已生成：包含 {len(harmful_items)} 个有害元素和 {len(random_sample)} 个随机抽取的非有害元素，共 {len(new_data)} 个元素。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-02-10T06:27:21.073550Z",
     "iopub.status.busy": "2025-02-10T06:27:21.073230Z",
     "iopub.status.idle": "2025-02-10T06:27:21.129106Z",
     "shell.execute_reply": "2025-02-10T06:27:21.128511Z",
     "shell.execute_reply.started": "2025-02-10T06:27:21.073530Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件已打乱，结果保存为 /mnt/workspace/our_work/ThirdVersion/result/qwen/topk=5/threshold=0.5/gte_Qwen2-1.5B-instruct/attack/mix/file/multiLang_renellm_mix_prompt_data_merged_our_work1.json\n"
     ]
    }
   ],
   "source": [
    "input_file = '/mnt/workspace/our_work/ThirdVersion/result/qwen/topk=5/threshold=0.5/gte_Qwen2-1.5B-instruct/attack/mix/file/multiLang_renellm_mix_prompt_data_merged_our_work1.json' \n",
    "import json\n",
    "import random\n",
    "\n",
    "# 定义输入和输出文件路径\n",
    "\n",
    "output_file = '/mnt/workspace/our_work/ThirdVersion/result/qwen/topk=5/threshold=0.5/gte_Qwen2-1.5B-instruct/attack/mix/file/multiLang_renellm_mix_prompt_data_merged_our_work1.json'  # 替换为你希望保存的输出文件路径\n",
    "\n",
    "# 读取 JSON 文件（假设 JSON 文件内容为列表）\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 随机打乱列表顺序\n",
    "random.shuffle(data)\n",
    "\n",
    "# 将打乱后的数据写入新的 JSON 文件\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"文件已打乱，结果保存为 {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-02-10T07:04:11.581152Z",
     "iopub.status.busy": "2025-02-10T07:04:11.580373Z",
     "iopub.status.idle": "2025-02-10T07:04:11.734475Z",
     "shell.execute_reply": "2025-02-10T07:04:11.733775Z",
     "shell.execute_reply.started": "2025-02-10T07:04:11.581103Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 135 unique reference values from file2\n",
      "Successfully filtered JSON. Found 135 matching items.\n",
      "Successfully filtered JSON. Found 135 matching items.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def filter_json_files(file1_path, file2_path, output_path=None):\n",
    "    try:\n",
    "        with open(file1_path, 'r', encoding='utf-8') as f1:\n",
    "            json1 = json.load(f1)\n",
    "\n",
    "        with open(file2_path, 'r', encoding='utf-8') as f2:\n",
    "            json2 = json.load(f2)\n",
    "\n",
    "        # 确保 file2 的数据是唯一的\n",
    "        reference_values = {list(item.values())[0] for item in json2}\n",
    "\n",
    "        # 统计 file1 里每个值的出现次数\n",
    "        matched_counts = Counter(list(item.values())[0] for item in json1 if list(item.values())[0] in reference_values)\n",
    "\n",
    "        # 打印匹配信息\n",
    "        print(f\"Extracted {len(reference_values)} unique reference values from file2\")\n",
    "        # for key, count in matched_counts.items():\n",
    "        #     print(f\"Value {key} matched {count} times in file1\")\n",
    "\n",
    "        # 过滤 file1\n",
    "        seen_values = set()\n",
    "        filtered_json = []\n",
    "        for item in json1:\n",
    "            key_value = list(item.values())[0]\n",
    "            # key_value = next((value for key, value in item.items() if \"renellm_prompt\" in key), None)\n",
    "            if key_value in reference_values and key_value not in seen_values:\n",
    "                filtered_json.append(item)\n",
    "                seen_values.add(key_value)  # 避免重复匹配\n",
    "\n",
    "        # 保存文件\n",
    "        if output_path:\n",
    "            with open(output_path, 'w', encoding='utf-8') as f_out:\n",
    "                json.dump(filtered_json, f_out, ensure_ascii=False, indent=2)\n",
    "\n",
    "        print(f\"Successfully filtered JSON. Found {len(filtered_json)} matching items.\")\n",
    "        return filtered_json\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Could not find file - {e}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error: Invalid JSON format - {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: An unexpected error occurred - {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths to your JSON files\n",
    "    file1_path = \"/mnt/workspace/our_work/ThirdVersion/result/qwen/topk10andawen1.5b/attack/mix/file/multiLang_renellm_mix_prompt_data_merged_our_work.json\"\n",
    "    file2_path = \"/mnt/workspace/our_work/ThirdVersion/result/qwen/topk=5/threshold=0.5/gte_Qwen2-1.5B-instruct/attack/mix/file/multiLang_renellm_mix_prompt_data_merged_our_work1.json\"\n",
    "    # output_path = \"/mnt/workspace/our_work/ThirdVersion/result/deepseek/topk=5/threshold=0.5/gte_Qwen2-1.5B-instruct/attack/mix/new_Cipher_renellm_mix_prompt_data_our_work.json\"\n",
    "    # file3_path=\"/mnt/workspace/our_work/dataset-25-1-16/wildjailbreak_final/defence/jailbreak_test/mix/multiLang_renellm_mix_prompt_data_merged_our_work.json\"\n",
    "    # Filter and save results\n",
    "    file4_path=\"/mnt/workspace/our_work/ThirdVersion/result/deepseek/topk=5/threshold=0.5/gte_Qwen2-1.5B-instruct/attack/mix/mix_attack_top10/multiLang_renellm_mix_prompt_data_merged_our_work.json\"\n",
    "    file5_path=\"/mnt/workspace/our_work/ThirdVersion/result/qwen/topk=3andqwen1.5b/attack/mix/file/multiLang_renellm_mix_prompt_data_merged_our_work.json\"\n",
    "    file6_path=\"/mnt/workspace/our_work/ThirdVersion/result/qwen/topk=5/threshold=0.4/gte_Qwen2-1.5B-instruct/attack/mix/file/multiLang_renellm_mix_prompt_data_merged_our_work.json\"\n",
    "    file7_path=\"/mnt/workspace/our_work/ThirdVersion/result/qwen/topk=5/threshold=0.6/gte_Qwen2-1.5B-instruct/attack/mix/file/multiLang_renellm_mix_prompt_data_merged_our_work.json\"\n",
    "    file8_path=\"/mnt/workspace/our_work/ThirdVersion/result/qwen/topk=5/threshold=0.7/gte_Qwen2-1.5B-instruct/attack/mix/file/multiLang_renellm_mix_prompt_data_merged_our_work.json\"\n",
    "    file9_path=\"/mnt/workspace/our_work/ThirdVersion/result/qwen/topk7andawen1.5b/attack/mix/file/multiLang_renellm_mix_prompt_data_merged_our_work.json\"\n",
    "    file10_path=\"/mnt/workspace/our_work/ThirdVersion/result/qwen/topk7andawen1.5b/attack/mix/file/multiLang_renellm_mix_prompt_data_merged_our_work.json\"\n",
    "    file11_path=\"/mnt/workspace/our_work/ThirdVersion/test_data/deepseek_14b/attack/mix/file/multiLang_renellm_mix_prompt_data_merged_our_work.json\"\n",
    "    file12_path=\"/mnt/workspace/our_work/ThirdVersion/test_data/qwen_plus/attack/mix/file/multiLang_renellm_mix_prompt_data_merged_our_work.json\"\n",
    "    filtered = filter_json_files(file1_path, file2_path, file1_path)\n",
    "    \n",
    "    if filtered is not None:\n",
    "        print(f\"Successfully filtered JSON. Found {len(filtered)} matching items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-02-10T06:44:56.820820Z",
     "iopub.status.busy": "2025-02-10T06:44:56.820471Z",
     "iopub.status.idle": "2025-02-10T06:44:56.926862Z",
     "shell.execute_reply": "2025-02-10T06:44:56.926263Z",
     "shell.execute_reply.started": "2025-02-10T06:44:56.820799Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重完成，原始数据 182 条，去重后 182 条，已保存至 /mnt/workspace/our_work/ThirdVersion/result/deepseek/topk=5/threshold=0.5/gte_Qwen2-1.5B-instruct/attack/mix/mix_attack_top10/multiLang_renellm_mix_prompt_data_merged_our_work.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def remove_duplicates(json_file, output_file):\n",
    "    # 读取 JSON 文件\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 去重（使用 set 不能直接处理字典，需要用 frozenset 或 tuple）\n",
    "    unique_data = list({json.dumps(item, sort_keys=True) for item in data})\n",
    "\n",
    "    # 解析回 JSON\n",
    "    unique_data = [json.loads(item) for item in unique_data]\n",
    "\n",
    "    # 保存去重后的 JSON\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(unique_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"去重完成，原始数据 {len(data)} 条，去重后 {len(unique_data)} 条，已保存至 {output_file}\")\n",
    "\n",
    "# 示例：替换为你的 JSON 文件路径\n",
    "input_json = \"/mnt/workspace/our_work/ThirdVersion/result/deepseek/topk=5/threshold=0.5/gte_Qwen2-1.5B-instruct/attack/mix/mix_attack_top10/multiLang_renellm_mix_prompt_data_merged_our_work.json\"\n",
    "output_json = \"/mnt/workspace/our_work/ThirdVersion/result/deepseek/topk=5/threshold=0.5/gte_Qwen2-1.5B-instruct/attack/mix/mix_attack_top10/multiLang_renellm_mix_prompt_data_merged_our_work.json\"\n",
    "\n",
    "remove_duplicates(input_json, output_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
